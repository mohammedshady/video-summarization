{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWRJTHj_c9dU"
      },
      "outputs": [],
      "source": [
        " !python3 -m pip install --upgrade --user ortools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4x7HZbPnxLR",
        "outputId": "93a2a109-12a7-453f-ad5d-385df9dae5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from os import PathLike\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from numpy import linalg\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "import csv\n",
        "import os\n",
        "import h5py\n",
        "import json\n",
        "from google.colab import drive\n",
        "from typing import Iterable, List\n",
        "from ortools.algorithms.python import knapsack_solver\n",
        "import numpy as np\n",
        "import h5py\n",
        "import json\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYoJm3fAn2c7"
      },
      "outputs": [],
      "source": [
        "feat_size = 1024\n",
        "normalization_rate = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKdO4_lOnIsm"
      },
      "outputs": [],
      "source": [
        "# Code for Feature Extraction\n",
        "\n",
        "class FeatureExtractor(object):\n",
        "    def __init__(self):\n",
        "        # pytorch recommended parameters\n",
        "        self.preprocess = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "        # use googlenet model with imagenet weights\n",
        "        self.model = models.googlenet(weights ='DEFAULT')\n",
        "        # remove last 2 layers for feature extraction\n",
        "        self.model = nn.Sequential(*list(self.model.children())[:-2])\n",
        "        self.model = self.model.cuda().eval()\n",
        "\n",
        "    def run(self, img: np.ndarray) -> np.ndarray:\n",
        "        # process frames to extract features\n",
        "        img = Image.fromarray(img)\n",
        "        img = self.preprocess(img)\n",
        "        batch = img.unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            feat = self.model(batch.cuda())\n",
        "            feat = feat.squeeze().cpu().numpy()\n",
        "\n",
        "        assert feat.shape == (feat_size,), f'Invalid feature shape {feat.shape}: expected {feat_size}'\n",
        "        # normalize frame features\n",
        "        feat /= linalg.norm(feat) + normalization_rate\n",
        "        return feat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfH7TYozpxpk"
      },
      "outputs": [],
      "source": [
        "class VideoPreprocessor(object):\n",
        "    # initialize feature extractor and sample rate for downsampling sequence\n",
        "    def __init__(self, sample_rate: int) -> None:\n",
        "        self.model = FeatureExtractor()\n",
        "        self.sample_rate = sample_rate\n",
        "    # function to read video and downsample the video\n",
        "    def get_features(self, video_path: PathLike):\n",
        "        video_path = Path(video_path)\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        assert cap is not None, f'Cannot open video: {video_path}'\n",
        "\n",
        "        features = []\n",
        "        n_frames = 0\n",
        "        # downsample the video\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if n_frames % self.sample_rate == 0:\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                feat = self.model.run(frame)\n",
        "                features.append(feat)\n",
        "\n",
        "            n_frames += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        features = np.array(features)\n",
        "        return n_frames, features\n",
        "    # extract change points and other features\n",
        "    def kts(self, n_frames, features):\n",
        "        seq_len = len(features)\n",
        "        picks = np.arange(0, seq_len) * self.sample_rate\n",
        "\n",
        "        # compute change points using KTS\n",
        "        kernel = np.matmul(features, features.T)\n",
        "        change_points, _ = cpd_auto(kernel, seq_len - 1, 1, verbose=False)\n",
        "        change_points *= self.sample_rate\n",
        "        change_points = np.hstack((0, change_points, n_frames))\n",
        "        begin_frames = change_points[:-1]\n",
        "        end_frames = change_points[1:]\n",
        "        change_points = np.vstack((begin_frames, end_frames - 1)).T\n",
        "\n",
        "        n_frame_per_seg = end_frames - begin_frames\n",
        "        return change_points, n_frame_per_seg, picks\n",
        "    # run the following functions for feature extraction\n",
        "    def run(self, video_path: PathLike):\n",
        "        n_frames, features = self.get_features(video_path)\n",
        "        cps, nfps, picks = self.kts(n_frames, features)\n",
        "        return n_frames, features, cps, nfps, picks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItO3yUfXnkxE"
      },
      "outputs": [],
      "source": [
        "# create dataset with new features\n",
        "video_titles = []\n",
        "with open(order_path) as fd:\n",
        "    reader = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
        "    for row in reader:\n",
        "        if(row[1] != \"video_id\"):\n",
        "            video_titles.append(row[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS_H-Bjnye2Z"
      },
      "outputs": [],
      "source": [
        "# define knapsack and the conversion of keyframe scores to keyshot summaries\n",
        "def knapsack(values: Iterable[int],\n",
        "             weights: Iterable[int],\n",
        "             capacity: int\n",
        "             ) -> List[int]:\n",
        "    solver = knapsack_solver.KnapsackSolver(\n",
        "        knapsack_solver.SolverType.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER, 'test'\n",
        "    )\n",
        "\n",
        "    values = list(values)\n",
        "    weights = list(weights)\n",
        "    capacity = int(capacity)\n",
        "\n",
        "    solver.init(values, [weights], [capacity])\n",
        "    solver.solve()\n",
        "    packed_items = [x for x in range(0, len(weights))\n",
        "                    if solver.best_solution_contains(x)]\n",
        "\n",
        "    return packed_items\n",
        "\n",
        "def get_keyshot_summ(frame_scores: np.ndarray,\n",
        "                     cps: np.ndarray,\n",
        "                     n_frames: int,\n",
        "                     nfps: np.ndarray,\n",
        "                     picks: np.ndarray,\n",
        "                     proportion: float = 0.2\n",
        "                     ) -> np.ndarray:\n",
        "\n",
        "\n",
        "    # Assign scores to video shots as the average of the frames.\n",
        "    seg_scores = np.zeros(len(cps), dtype=np.int32)\n",
        "    for seg_idx, (first, last) in enumerate(cps):\n",
        "        scores = frame_scores[first:last + 1]\n",
        "        seg_scores[seg_idx] = int(1000 * scores.mean())\n",
        "\n",
        "    # Apply knapsack algorithm to find the best shots\n",
        "    limits = int(n_frames * proportion)\n",
        "    packed = knapsack(seg_scores, nfps, limits)\n",
        "\n",
        "    # Get key-shot based summary\n",
        "    summary = np.zeros(n_frames, dtype=np.bool_)\n",
        "    for seg_idx in packed:\n",
        "        first, last = cps[seg_idx]\n",
        "        summary[first:last + 1] = True\n",
        "\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWAHbL1gqkkl",
        "outputId": "d07ffec4-67cb-4539-f3e2-ad8f8ec365a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:00<00:00, 159MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "working on video  AwmHb44_ouw   video_1  of  50\n",
            "(20, 10597)\n",
            "working on video  98MoyGZKHXc   video_2  of  50\n",
            "(20, 4688)\n",
            "working on video  J0nA4VgnoCo   video_3  of  50\n",
            "(20, 14019)\n",
            "working on video  gzDbaEs1Rlg   video_4  of  50\n",
            "(20, 7210)\n",
            "working on video  XzYM3PfTM4w   video_5  of  50\n",
            "(20, 3327)\n",
            "working on video  HT5vyqe0Xaw   video_6  of  50\n",
            "(20, 9671)\n",
            "working on video  sTEELN-vY30   video_7  of  50\n",
            "(20, 4468)\n",
            "working on video  vdmoEJ5YbrQ   video_8  of  50\n",
            "(20, 9870)\n",
            "working on video  xwqBXPGE9pQ   video_9  of  50\n",
            "(20, 7010)\n",
            "working on video  akI8YFjEmUw   video_10  of  50\n",
            "(20, 3995)\n",
            "working on video  i3wAGJaaktw   video_11  of  50\n",
            "(20, 4700)\n",
            "working on video  Bhxk-O1Y7Ho   video_12  of  50\n",
            "(20, 13511)\n",
            "working on video  0tmA_C6XwfM   video_13  of  50\n",
            "(20, 3532)\n",
            "working on video  3eYKfiOEJNs   video_14  of  50\n",
            "(20, 4853)\n",
            "working on video  xxdtq8mxegs   video_15  of  50\n",
            "(20, 4324)\n",
            "working on video  WG0MBPpPC6I   video_16  of  50\n",
            "(20, 9534)\n",
            "Invalid label of size 9534: expected 9535\n",
            "working on video  Hl-__g2gn_A   video_17  of  50\n",
            "(20, 5846)\n",
            "working on video  Yi4Ij2NM7U4   video_18  of  50\n",
            "(20, 9731)\n",
            "working on video  37rzWOQsNIw   video_19  of  50\n",
            "(20, 5742)\n",
            "working on video  LRw_obCPUt0   video_20  of  50\n",
            "(20, 6241)\n",
            "working on video  cjibtmSLxQ4   video_21  of  50\n",
            "(20, 19406)\n",
            "working on video  b626MiF1ew4   video_22  of  50\n",
            "(20, 5661)\n",
            "working on video  XkqCExn6_Us   video_23  of  50\n",
            "(20, 5631)\n",
            "working on video  GsAD1KT1xo8   video_24  of  50\n",
            "(20, 4356)\n",
            "working on video  PJrm840pAUI   video_25  of  50\n",
            "(20, 6580)\n",
            "working on video  91IHQYk1IQM   video_26  of  50\n",
            "(20, 3312)\n",
            "working on video  RBCABdttQmI   video_27  of  50\n",
            "(20, 10917)\n",
            "working on video  z_6gVvQb2d0   video_28  of  50\n",
            "(20, 8281)\n",
            "working on video  fWutDQy1nnY   video_29  of  50\n",
            "(20, 17527)\n",
            "working on video  4wU_LUjG5Ic   video_30  of  50\n",
            "(20, 4005)\n",
            "working on video  VuWGsYPqAX8   video_31  of  50\n",
            "(20, 5412)\n",
            "working on video  JKpqYvAdIsw   video_32  of  50\n",
            "(20, 3802)\n",
            "working on video  xmEERLqJ2kU   video_33  of  50\n",
            "(20, 13365)\n",
            "working on video  byxOvuiIJV0   video_34  of  50\n",
            "(20, 3705)\n",
            "working on video  _xMr-HKMfVA   video_35  of  50\n",
            "(20, 4463)\n",
            "working on video  WxtbjNsCQ8A   video_36  of  50\n",
            "(20, 7959)\n",
            "working on video  uGu_10sucQo   video_37  of  50\n",
            "(20, 4009)\n",
            "working on video  EE-bNr36nyA   video_38  of  50\n",
            "(20, 2941)\n",
            "working on video  Se3oxnaPsz0   video_39  of  50\n",
            "(20, 4165)\n",
            "Invalid label of size 4165: expected 4166\n",
            "working on video  oDXZc0tZe04   video_40  of  50\n",
            "(20, 11414)\n",
            "working on video  qqR6AEXwxoQ   video_41  of  50\n",
            "(20, 8073)\n",
            "working on video  EYqVtI9YWJA   video_42  of  50\n",
            "(20, 5939)\n",
            "working on video  eQu1rNs0an0   video_43  of  50\n",
            "(20, 4931)\n",
            "working on video  JgHubY5Vw3Y   video_44  of  50\n",
            "(20, 4304)\n",
            "working on video  iVt07TCkFM0   video_45  of  50\n",
            "(20, 2500)\n",
            "working on video  E11zDS9XGzg   video_46  of  50\n",
            "(20, 15307)\n",
            "working on video  NyBmCxDoHJU   video_47  of  50\n",
            "(20, 4740)\n",
            "working on video  kLxoNp-UchI   video_48  of  50\n",
            "(20, 3896)\n",
            "working on video  jcoYJXDG9sw   video_49  of  50\n",
            "(20, 5971)\n",
            "working on video  -esJrBWj2d8   video_50  of  50\n",
            "(20, 6912)\n",
            "Dataset saved to /content/drive/MyDrive/datasets/Datasets Feature Extraction/tvsum-0.2-(x)norm.h5\n"
          ]
        }
      ],
      "source": [
        "#initialize preprocessor for video frames\n",
        "video_proc = VideoPreprocessor(15)\n",
        "\n",
        "#create dataset file and write features of the dataset\n",
        "with h5py.File(file_name, 'w') as h5out:\n",
        "    for idx, video_title in enumerate(video_titles):\n",
        "\n",
        "        video_key = f'video_{idx+1}'\n",
        "        print(\"working on video \", video_title, \" \", video_key, \" of \", len(video_titles))\n",
        "\n",
        "        video_path = os.path.join(videos_path, video_title + \".mp4\")\n",
        "        n_frames, features, cps, nfps, picks = video_proc.run(video_path)\n",
        "\n",
        "        label_path = os.path.join(anno_path, video_title +\".json\")\n",
        "\n",
        "        #get video labels (annotations)\n",
        "        with open(label_path, 'r') as file:\n",
        "            json_data = json.load(file)\n",
        "            user_summary = np.array(json_data[\"user_summary\"],dtype=np.float32)\n",
        "\n",
        "            # Ensure Equal Shape\n",
        "            _, label_n_frames = user_summary.shape\n",
        "\n",
        "            print(user_summary.shape)\n",
        "            if (label_n_frames < n_frames):\n",
        "                print(f'Invalid label of size {label_n_frames}: expected {n_frames}')\n",
        "                user_summary = np.pad(user_summary, ((0, 0), (0,  n_frames - label_n_frames)), mode='constant', constant_values=1)\n",
        "            elif (label_n_frames > n_frames):\n",
        "                print(f'Invalid label of size {label_n_frames}: expected {n_frames}')\n",
        "                user_summary = user_summary[:, :n_frames]\n",
        "\n",
        "            # # Normalize the mean of the annotations\n",
        "            # user_summary -= user_summary.min()\n",
        "            # user_summary /= user_summary.max()\n",
        "\n",
        "            gtscore = np.mean(user_summary[:, ::15], axis=0)\n",
        "\n",
        "            # convert annotations into summaries\n",
        "            bool_summary = []\n",
        "            for summary in user_summary:\n",
        "                bool_summary.append(get_keyshot_summ(summary,cps,n_frames,nfps,picks))\n",
        "            bool_summary = np.array(bool_summary,dtype=np.float32)\n",
        "\n",
        "\n",
        "        #write dataset to h5 file\n",
        "        h5out.create_dataset(f'{video_key}/features', data=features)\n",
        "        h5out.create_dataset(f'{video_key}/gtscore', data=gtscore)\n",
        "        h5out.create_dataset(f'{video_key}/user_summary', data=bool_summary)\n",
        "        h5out.create_dataset(f'{video_key}/change_points', data=cps)\n",
        "        h5out.create_dataset(f'{video_key}/n_frame_per_seg', data=nfps)\n",
        "        h5out.create_dataset(f'{video_key}/n_frames', data=n_frames)\n",
        "        h5out.create_dataset(f'{video_key}/picks', data=picks)\n",
        "        h5out.create_dataset(f'{video_key}/video_name', data=video_title)\n",
        "\n",
        "    print(f'Dataset saved to {file_name}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}