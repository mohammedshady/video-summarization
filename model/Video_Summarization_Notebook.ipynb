{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLRb-BAlapnq"
      },
      "source": [
        "# Import Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLw4bJp9Vwti",
        "outputId": "5ad57438-8938-4f9e-d03c-9a98ac939b06"
      },
      "outputs": [],
      "source": [
        " # you have to run this first and then after it installs restart session then you can run the rest of the code blocks\n",
        "!python3 -m pip install --upgrade --user ortools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBroqyqWHWTY",
        "outputId": "06e7c30a-f616-4104-fae8-2e8ca985d00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epCeN52tFXPm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import h5py\n",
        "import yaml\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from os import PathLike\n",
        "from pathlib import Path\n",
        "import torch.nn.init as init\n",
        "from typing import Any, List, Dict\n",
        "from torch.nn import functional as F\n",
        "from ortools.algorithms.python import knapsack_solver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U99NBeHbbzSy"
      },
      "source": [
        "# Helper Logic-less Functions\n",
        "### Functions to make the code look readable and better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFFTvoCyMe5g"
      },
      "outputs": [],
      "source": [
        "#helper logic-less functions (read/write)\n",
        "\n",
        "def load_yaml(path: PathLike) -> Any:\n",
        "    with open(path) as f:\n",
        "        obj = yaml.safe_load(f)\n",
        "    return obj\n",
        "\n",
        "def dump_yaml(obj: Any, path: PathLike) -> None:\n",
        "    with open(path, 'w') as f:\n",
        "        yaml.dump(obj, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGltIiafa0rI"
      },
      "source": [
        "# Helper Classes\n",
        "\n",
        "### `VideoDataset` : used for reading files from the dataset into the memory.\n",
        "### `Data Loader` : used for shuffeling and loading batches of these VideoDataset to help in training and evaluating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsPa374DPjeu"
      },
      "outputs": [],
      "source": [
        "# Helper Classes for Data Loading and proccessing\n",
        "\n",
        "class VideoDataset(object):\n",
        "    # constructor to set class varaibles\n",
        "    def __init__(self, keys: List[str]):\n",
        "        self.keys = keys\n",
        "        self.datasets = self.get_datasets(keys)\n",
        "    # getter to load data from the dataset file into the memory\n",
        "    def __getitem__(self, index):\n",
        "        key = self.keys[index]\n",
        "        video_path = Path(key)\n",
        "        dataset_name = str(video_path.parent)\n",
        "        video_name = video_path.name\n",
        "        video_file = self.datasets[dataset_name][video_name]\n",
        "\n",
        "        seq = video_file['features'][...].astype(np.float32)\n",
        "        gtscore = video_file['gtscore'][...].astype(np.float32)\n",
        "        cps = video_file['change_points'][...].astype(np.int32)\n",
        "        n_frames = video_file['n_frames'][...].astype(np.int32)\n",
        "        nfps = video_file['n_frame_per_seg'][...].astype(np.int32)\n",
        "        picks = video_file['picks'][...].astype(np.int32)\n",
        "        user_summary = None\n",
        "        if 'user_summary' in video_file:\n",
        "            user_summary = video_file['user_summary'][...].astype(np.float32)\n",
        "\n",
        "        gtscore -= gtscore.min()\n",
        "        gtscore /= gtscore.max()\n",
        "\n",
        "        return key, seq, gtscore, cps, n_frames, nfps, picks, user_summary\n",
        "\n",
        "    # return dataset keys length\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    # open dataset h5 file in read mode\n",
        "    @staticmethod\n",
        "    def get_datasets(keys: List[str]) -> Dict[str, h5py.File]:\n",
        "        dataset_paths = {str(Path(key).parent) for key in keys}\n",
        "        datasets = {path: h5py.File(path, 'r') for path in dataset_paths}\n",
        "        return datasets\n",
        "\n",
        "\n",
        "class DataLoader(object):\n",
        "    # constructor to set class varaibles\n",
        "    def __init__(self, dataset: VideoDataset, shuffle: bool):\n",
        "        self.dataset = dataset\n",
        "        self.shuffle = shuffle\n",
        "        self.data_idx = list(range(len(self.dataset)))\n",
        "\n",
        "    # shuffle data on iterate for training\n",
        "    def __iter__(self):\n",
        "        self.iter_idx = 0\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.data_idx)\n",
        "        return self\n",
        "\n",
        "    # processes the next batch when looping on data for training and testing\n",
        "    def __next__(self):\n",
        "        if self.iter_idx == len(self.dataset):\n",
        "            raise StopIteration\n",
        "        curr_idx = self.data_idx[self.iter_idx]\n",
        "        batch = self.dataset[curr_idx]\n",
        "        self.iter_idx += 1\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGMgCCMa9_Xw"
      },
      "source": [
        "# Hepler logic Functions\n",
        "### `knapsack`: to find the best segments in the video with a specific propotion\n",
        "###`generate_summary` : This function is used to convert key fragment scores into shot level summaries.\n",
        "### `evaluate_summary`: this function takes both user summary and machine summary and returns the preformance using f-score metric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4soWEQOsyINx"
      },
      "outputs": [],
      "source": [
        "# initialize knapsack from ortools library\n",
        "osolver = knapsack_solver.KnapsackSolver(\n",
        "    knapsack_solver.SolverType.KNAPSACK_DYNAMIC_PROGRAMMING_SOLVER, 'test'\n",
        ")\n",
        "\n",
        "def knapsack_ortools(values, weights,capacity ):\n",
        "    scale = 1000\n",
        "    values = np.array(values)\n",
        "    weights = np.array(weights)\n",
        "    values = (values * scale).astype(np.int_)\n",
        "    weights = (weights).astype(np.int_)\n",
        "    capacity = capacity\n",
        "\n",
        "    osolver.init(values.tolist(), [weights.tolist()], [capacity])\n",
        "    osolver.solve()\n",
        "    # get the knapsack picks\n",
        "    packed_items = [x for x in range(0, len(weights))\n",
        "                    if osolver.best_solution_contains(x)]\n",
        "\n",
        "    return packed_items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJPfLdtIpoyE"
      },
      "outputs": [],
      "source": [
        "# Convert from keyframes to keyshot summaries\n",
        "\n",
        "def generate_summary(ypred, cps, n_frames, nfps, positions, proportion=0.2):\n",
        "    # upscale the downsampled sequence\n",
        "    n_segs = cps.shape[0]\n",
        "    frame_scores = np.zeros((n_frames), dtype=np.float32)\n",
        "    if positions.dtype != int:\n",
        "        positions = positions.astype(np.int32)\n",
        "    if positions[-1] != n_frames:\n",
        "        positions = np.concatenate([positions, [n_frames]])\n",
        "    for i in range(len(positions) - 1):\n",
        "        pos_left, pos_right = positions[i], positions[i+1]\n",
        "        if i == len(ypred):\n",
        "            frame_scores[pos_left:pos_right] = 0\n",
        "        else:\n",
        "            frame_scores[pos_left:pos_right] = ypred[i]\n",
        "\n",
        "    # take the average across change points\n",
        "    seg_score = []\n",
        "    for seg_idx in range(n_segs):\n",
        "        start, end = int(cps[seg_idx,0]), int(cps[seg_idx,1]+1)\n",
        "        scores = frame_scores[start:end]\n",
        "        seg_score.append(float(scores.mean()))\n",
        "\n",
        "    # get the knapsack picks\n",
        "    limits = int(math.floor(n_frames * proportion))\n",
        "    packed = knapsack_ortools(seg_score, nfps, n_segs, limits)\n",
        "\n",
        "    # convert the chosen segments into binary summary\n",
        "    summary = np.zeros(n_frames, dtype=np.bool_)\n",
        "    for seg_idx in packed:\n",
        "        first, last = cps[seg_idx]\n",
        "        summary[first:last + 1] = True\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uNGA6p4p0aV"
      },
      "outputs": [],
      "source": [
        "def evaluate_summary(machine_summary, user_summaries):\n",
        "    # Ensure inputs are in float32 format\n",
        "    machine_summary = machine_summary.astype(np.float32)\n",
        "    user_summaries = user_summaries.astype(np.float32)\n",
        "    n_users, n_frames = user_summaries.shape\n",
        "\n",
        "    # Binarize the summaries (1 if > 0, else 0)\n",
        "    machine_summary[machine_summary > 0] = 1\n",
        "    user_summaries[user_summaries > 0] = 1\n",
        "\n",
        "    # Adjust machine summary length to match user summary length\n",
        "    if len(machine_summary) > n_frames:\n",
        "        machine_summary = machine_summary[:n_frames]  # Truncate if too long\n",
        "    elif len(machine_summary) < n_frames:\n",
        "        zero_padding = np.zeros(n_frames - len(machine_summary))\n",
        "        machine_summary = np.concatenate([machine_summary, zero_padding])  # Pad with zeros if too short\n",
        "    \n",
        "    # Compute F-score, precision, and recall for each user's summary\n",
        "    f_scores = [],precisions = [],recalls = []\n",
        "    for user_idx in range(n_users):\n",
        "        user_summary = user_summaries[user_idx, :]\n",
        "        overlap_duration = (machine_summary * user_summary).sum()\n",
        "        precision = overlap_duration / (machine_summary.sum() + 1e-8)\n",
        "        recall = overlap_duration / (user_summary.sum() + 1e-8)\n",
        "\n",
        "        # Avoid division by zero issues\n",
        "        f_score = 0. if (precision == 0 and recall == 0) else (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "        f_scores.append(f_score)\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    # Compute the average F-score, precision, and recall across all users\n",
        "    avg_f_score = np.mean(f_scores)\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_recall = np.mean(recalls)\n",
        "\n",
        "    return avg_f_score, avg_precision, avg_recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMMfwiw0k5dO"
      },
      "source": [
        "#VideoSummarizerNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IweSlaYqkfTi"
      },
      "outputs": [],
      "source": [
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size=1024, output_size=1024):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        # define attention params\n",
        "        self.m = input_size\n",
        "        self.output_size = output_size\n",
        "        # define 3 vectors (K,Q,V)\n",
        "        self.K = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        self.Q = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        self.V = nn.Linear(in_features=self.m, out_features=self.output_size, bias=False)\n",
        "        # define output linear transformation layer\n",
        "        self.output_linear = nn.Linear(in_features=self.output_size, out_features=self.m, bias=False)\n",
        "        self.drop50 = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # process the features through 3 layers k,q,v\n",
        "        K = self.K(x)\n",
        "        Q = self.Q(x)\n",
        "        V = self.V(x)\n",
        "        # normalize the attention scores\n",
        "        Q *= 0.06\n",
        "        logits = torch.matmul(Q, K.transpose(1,0))\n",
        "        attention_weights = nn.functional.softmax(logits, dim=-1)\n",
        "        weights = self.drop50(attention_weights)\n",
        "        # calculate final weighted values\n",
        "        y = torch.matmul(weights, V)\n",
        "\n",
        "        y = self.output_linear(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "class VideoSummarizerNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VideoSummarizerNetwork, self).__init__()\n",
        "        self.input_size = 1024\n",
        "        self.hidden_size = 1024\n",
        "        \n",
        "        self.attention_layer = SelfAttention(input_size=self.input_size, output_size=self.input_size)\n",
        "        self.fc1 = nn.Linear(in_features=self.input_size, out_features=self.hidden_size)\n",
        "        self.fc2 = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "        self.norm_input = nn.LayerNorm(self.input_size)\n",
        "        self.norm_hidden = nn.LayerNorm(self.hidden_size)\n",
        "\n",
        "    def forward(self, video_features):\n",
        "        feature_size = video_features.shape[2]  # Extract the feature size (third dimension)\n",
        "    \n",
        "        # Flatten the sequence into a batch of frames\n",
        "        video_features = video_features.view(-1, feature_size)\n",
        "        attention_output = self.attention_layer(video_features)\n",
        "        residual_output = attention_output + video_features  # Residual connection (adding input to attention output)\n",
        "        # Apply dropout and layer normalization on the residual output\n",
        "        normalized_output = self.dropout(residual_output)\n",
        "        normalized_output = self.norm_input(normalized_output)\n",
        "        \n",
        "        # Pass through the first fully connected layer, apply ReLU and dropout\n",
        "        hidden_output = self.fc1(normalized_output)\n",
        "        hidden_output = self.relu(hidden_output)\n",
        "        hidden_output = self.dropout(hidden_output)\n",
        "        hidden_output = self.norm_hidden(hidden_output)\n",
        "        \n",
        "        # Pass through the second fully connected layer to get the final output\n",
        "        output = self.fc2(hidden_output)\n",
        "        output = self.sigmoid(output).view(1, -1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        # Make a prediction for a given sequence\n",
        "        predictions = self(sequence)\n",
        "        predictions = predictions[0].detach().cpu().numpy()\n",
        "        return predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZHmOJMI2fD_"
      },
      "source": [
        "## `Weights initialization` help in getting reproducible results  each time we train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q89k-7vjkWRH"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname == 'Linear':\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2.0))\n",
        "        if m.bias is not None:\n",
        "            init.constant_(m.bias, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzA10_vagaXo"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09M4gKd3ll6R"
      },
      "outputs": [],
      "source": [
        "def train(split,split_idx):\n",
        "\n",
        "    print(\"Initializing VideoSummarizerNetwork model and optimizer...\")\n",
        "    #enable train mode\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss().cuda()\n",
        "    #initialize optimizer with the hyperparameters\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr= 0.00005, weight_decay= 0.00001)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    max_val_fscore = 0\n",
        "    max_val_fscore_epoch = 0\n",
        "    # get training keys and load the videos in train loader\n",
        "    train_set = VideoDataset(split['train_keys'])\n",
        "    train_loader = DataLoader(train_set, shuffle=True)\n",
        "    # get testing keys and load the videos in test loader\n",
        "    val_set = VideoDataset(split['test_keys'])\n",
        "    val_loader = DataLoader(val_set, shuffle=False)\n",
        "    # run the training process for 120 epochs\n",
        "    for epoch in range(120):\n",
        "\n",
        "        print(\"Epoch: {0:6}\".format(str(epoch)+\"/\"+str(120)), end='')\n",
        "        model.train()\n",
        "\n",
        "        set_loss = []\n",
        "\n",
        "        for _, seq, gtscore, change_points, n_frames, nfps, picks, user_summary in train_loader:\n",
        "            # prepare input for model and target for loss calculation\n",
        "            seq = torch.from_numpy(seq).unsqueeze(0).cuda()\n",
        "            target = torch.from_numpy(gtscore).unsqueeze(0).cuda()\n",
        "            # predict based on seq(features)\n",
        "            y = model(seq)\n",
        "            # compare model prediction and actual lables\n",
        "            loss = criterion(y, target)\n",
        "            # record loss of each video in each epoch\n",
        "            set_loss.append(float(loss))\n",
        "            # do backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Evaluate test dataset and save model with highest fscore\n",
        "        val_fscore = eval(model,val_loader)\n",
        "        if max_val_fscore < val_fscore:\n",
        "            max_val_fscore = val_fscore\n",
        "            max_val_fscore_epoch = epoch\n",
        "            #torch.save(model.state_dict(), str(f'{saved_model_split}{split_idx}.pt'))\n",
        "\n",
        "\n",
        "        print(\"   Train loss: {0:.05f}\".format(np.mean(set_loss)), end='')\n",
        "        print('   Test F-score avg/max: {0:0.5}/{1:0.5}'.format(val_fscore, max_val_fscore))\n",
        "\n",
        "\n",
        "    return max_val_fscore, max_val_fscore_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td64TjelgfCg"
      },
      "source": [
        "#Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzQvrm5QoElD"
      },
      "outputs": [],
      "source": [
        "def eval(model, val_loader):\n",
        "\n",
        "    # put the model in evaluation mode\n",
        "    model.eval()\n",
        "    val_scores = []\n",
        "\n",
        "    # start the evaluation process without gradient descnet\n",
        "    with torch.no_grad():\n",
        "        #loop over testing videos\n",
        "        for test_key, seq, gtscore, cps, n_frames, nfps, picks, user_summary in val_loader:\n",
        "            # prepare for prediction and loss calculation\n",
        "            seq = torch.from_numpy(seq).unsqueeze(0).float().cuda()\n",
        "            # predict scores of the video i\n",
        "            y = model(seq)\n",
        "            prob = y[0].detach().cpu().numpy()\n",
        "            # convert scores to keyshot summary\n",
        "            pred_summary = generate_summary(prob, cps, n_frames, nfps, picks)\n",
        "            # get fscore of the summary\n",
        "            fm,_,_ = evaluate_summary(pred_summary, user_summary)\n",
        "\n",
        "            val_scores.append(fm)\n",
        "    # return the average of all videos in the test set\n",
        "    return np.mean(val_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMt-t1UhbLfW"
      },
      "source": [
        "# Start Model Training and Evaluation\n",
        "`initialize Model`: this code initializes a the model for video summarization, ensures reproducibility by setting random seeds, and sets up GPU cuda device\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZW7IaaG-gjG"
      },
      "outputs": [],
      "source": [
        "def initializeModel():\n",
        "  #configure random seed for numpy and torch and random libraries\n",
        "  rnd_seed = 12345\n",
        "  random.seed(rnd_seed)\n",
        "  np.random.seed(rnd_seed)\n",
        "  torch.manual_seed(rnd_seed)\n",
        "\n",
        "  #initialize model weights\n",
        "  model = VideoSummarizerNetwork()\n",
        "  model.eval()\n",
        "  model.apply(weights_init)\n",
        "\n",
        "  #configure cuda device for gpu acceleration\n",
        "  cuda_device = 0\n",
        "  torch.cuda.set_device(cuda_device)\n",
        "  torch.cuda.manual_seed(rnd_seed)\n",
        "  model.cuda()\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THT83z94vVIy",
        "outputId": "150725f2-c42c-4dac-8643-8b93e97a9c6a"
      },
      "outputs": [],
      "source": [
        "# dataset splits file\n",
        "dataset_path = \"/content/drive/MyDrive/datasets/tvsum - Copy.yml\"\n",
        "\n",
        "# load splits in memory\n",
        "split_path = Path(dataset_path)\n",
        "splits = load_yaml(split_path)\n",
        "\n",
        "avg_eval_scores = 0\n",
        "\n",
        "# initialize model, train on each split and save average f-score across 5 splits\n",
        "for split_idx, split in enumerate(splits):\n",
        "    model = initializeModel()\n",
        "    print(f'Start training on {split_path.stem}: split {split_idx}')\n",
        "    fscore, fscore_epoch = train(split,split_idx)\n",
        "    avg_eval_scores += fscore\n",
        "avg_eval_scores /= len(splits)\n",
        "\n",
        "print(f'Training done on {split_path.stem}. F-score: {avg_eval_scores:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90cfFcj6VF3H"
      },
      "source": [
        "# Model Inference\n",
        "### 1- we navigate into cloud directory to load the code of KTS that is used to preprocess videos before inference process\n",
        "\n",
        "### 2- then we load the model and preprocess the data and build video summary from the model prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ldGNcWnyw2Ov",
        "outputId": "1f739ee7-0373-41fe-8f70-e9e3c99b0818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Colab Notebooks/')\n",
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BdpWYaK5SkB"
      },
      "outputs": [],
      "source": [
        "from kts import VideoPreprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90St1kQxVL3C",
        "outputId": "e2219b60-b05f-41a7-8877-efe56fa51003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting summary ...\n",
            "Writing summary video ...\n"
          ]
        }
      ],
      "source": [
        "video_path = \"/content/drive/MyDrive/datasets/video/sTEELN-vY30.mp4\"\n",
        "save_path = \"/content/drive/MyDrive/datasets/output/sTEELN-vY30.mp4\"\n",
        "model_path = \"/content/drive/MyDrive/datasets/model-trained/our-attention-vas0.pt\"\n",
        "\n",
        "\n",
        "model = VideoSummarizerNetwork()\n",
        "model = model.eval().to(\"cpu\")\n",
        "state_dict = torch.load(model_path,map_location=lambda storage, loc: storage)\n",
        "\n",
        "\n",
        "#preprocess the video\n",
        "video_proc = VideoPreprocessor(15)\n",
        "n_frames, seq, cps, nfps, picks = video_proc.run(video_path)\n",
        "seq_len = len(seq)\n",
        "\n",
        "print('Predicting Scores ...')\n",
        "\n",
        "with torch.no_grad():\n",
        "    seq_torch = torch.from_numpy(seq).unsqueeze(0).to(\"cpu\")\n",
        "    pred_cls = model.predict(seq_torch)\n",
        "    pred_summ = generate_summary(pred_cls, cps, n_frames, nfps, picks)\n",
        "print('Writing Video ...')\n",
        "\n",
        "# load original video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# create summary video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))\n",
        "\n",
        "frame_idx = 0\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if pred_summ[frame_idx]:\n",
        "        out.write(frame)\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "out.release()\n",
        "cap.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
